{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sistema de Recomendación con KNN -> MovieLens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PAQUETES REQUERIDOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pip\n",
    "pip.main(['install', 'scikit-surprise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import KNNBasic\n",
    "from surprise import accuracy\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANALISIS EXPLORATORIO (EDA)**\n",
    "\n",
    "Primero hacemos una exploración descriptiva de nuestros datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CARGA DE DATOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el dataset MovieLens 100k\n",
    "# Estructura (usuario, ítem, rating, timestamp)\n",
    "data = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Mostrar los datos</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el conjunto de datos en un dataframe\n",
    "df = pd.DataFrame(data.raw_ratings, columns=['user_id', 'item_id', 'rating', 'timestamp'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Visualizar descripción de los datos</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    print(col,' has nulls =>', df['user_id'].isnull().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Convertir datos no númericos a numéricos</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['user_id'] = pd.to_numeric(df['user_id'])\n",
    "df['item_id'] = pd.to_numeric(df['item_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Mostrar los datos nueva vez</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Eliminar repeticiones y datos nulos</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_columns = df.columns[df.isnull().any()]\n",
    "if null_columns.size > 0:\n",
    "    print('Eliminando valores nulos...', end=' ')\n",
    "    df.dropna(inplace=True)\n",
    "    print('Valores nulos eliminados')\n",
    "else:\n",
    "    print('No hay valores nulos')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "are_duplicates = df.duplicated()\n",
    "if True in are_duplicates.values:\n",
    "    print('Eliminando duplicados...', end=' ')\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    print('Valores duplicados eliminados')\n",
    "else:\n",
    "    print('No hay duplicados')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Distribución de los ratings</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='rating', data=df)\n",
    "plt.title('Distribución de Ratings en MovieLens 100k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Separar los datos en trainset y testset</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Definir parámetros para los modelos</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {}\n",
    "for opt in ['cosine', 'pearson', 'msd', 'pearson_baseline']:\n",
    "    optx = {\n",
    "        #cosine,pearson,msd,sd\n",
    "        'name': opt, \n",
    "        # True si la similitud es entre usuarios, False si es entre ítems \n",
    "        'user_based': True\n",
    "    }\n",
    "    options.update({opt:optx})\n",
    "\n",
    "knn_cosine = KNNBasic(k=50, min_k=10, sim_options=options.get('cosine'))\n",
    "knn_pearson = KNNBasic(k=50, min_k=10, sim_options=options.get('pearson'))\n",
    "knn_msd = KNNBasic(k=50, min_k=10, sim_options=options.get('msd'))\n",
    "knn_pearson_baseline = KNNBasic(k=50, min_k=10, sim_options=options.get('pearson_baseline'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Entrenar modelos KNN</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cosine.fit(trainset=trainset)\n",
    "knn_pearson.fit(trainset=trainset)\n",
    "knn_msd.fit(trainset=trainset)\n",
    "knn_pearson_baseline.fit(trainset=trainset)\n",
    "\n",
    "knn_models = {'cosine':knn_cosine, 'pearson':knn_pearson, 'msd':knn_msd, 'pearson_baseline':knn_pearson_baseline}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Hacer predicciones en los modelos</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_cosine = knn_cosine.test(testset)\n",
    "predictions_pearson = knn_pearson.test(testset)\n",
    "predictions_msd = knn_msd.test(testset)\n",
    "predictions_pearson_baseline = knn_pearson_baseline.test(testset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Calcular el MAE(Mean Absolute Error) y RMSE(Root Mean Squared Error)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses = []\n",
    "maes = []\n",
    "for prediction in [predictions_cosine, predictions_pearson, predictions_msd, predictions_pearson_baseline]:\n",
    "    rmse = accuracy.rmse(prediction, verbose=False)\n",
    "    mae = accuracy.mae(prediction, verbose=False)\n",
    "    rmses.append(rmse)\n",
    "    maes.append(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Mostrar el MAE y RMSE de cada configuración de modelo</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(data=[(rmse, mae) for rmse,mae in zip(rmses, maes)], columns=['MAE','RMSE'], index=['cosine','pearson','msd','pearson_baseline'])\n",
    "df_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>Un MAE bajo indica que, en promedio, las predicciones del modelo están cerca de los valores reales. Esto es generalmente deseable y significa que el modelo tiene un buen rendimiento en la predicción.</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>Un RMSE bajo indica que las predicciones del modelo son generalmente cercanas a los valores reales, lo que es deseable. Un RMSE bajo sugiere que el modelo tiene un buen desempeño en la predicción.</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Para nuestro caso se evidencia que el mejor <code>MAE/RMSE</code> lo tiene el modelo que aplica el <code>MSD</code></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Obtener la matriz de similaridad</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_cosine.compute_similarities()\n",
    "similarity_matrix = knn_models.get('msd').sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a DataFrame para facilitar la visualización\n",
    "sim_df = pd.DataFrame(similarity_matrix)\n",
    "\n",
    "# Visualizar la matriz de similitud con un mapa de calor\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(sim_df, cmap='hot', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.title('Matriz de Similitud')\n",
    "plt.xlabel('Ítems')\n",
    "plt.ylabel('Ítems')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Comparación de RMSE: Entrenamiento vs Prueba (MSD)</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer predicciones en el conjunto de entrenamiento\n",
    "train_predictions = knn_models.get('msd').test(trainset.build_testset())\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "test_predictions = knn_models.get('msd').test(testset)\n",
    "\n",
    "train_rmse = accuracy.rmse(train_predictions, verbose=False)\n",
    "test_rmse = accuracy.rmse(test_predictions, verbose=False)\n",
    "\n",
    "labels = ['Entrenamiento', 'Prueba']\n",
    "rmse_values = [train_rmse, test_rmse]\n",
    "\n",
    "plt.bar(labels, rmse_values, color=['red', 'green'])\n",
    "plt.title('Comparación de RMSE: Entrenamiento vs Prueba (MSD)')\n",
    "plt.ylabel('RMSE')\n",
    "plt.ylim(0, max(rmse_values) + 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Recomendación de una película</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendacion(user_id, knn_model, n_recommendations=5):\n",
    "    # Obtener las películas que el usuario ya ha calificado\n",
    "    user_ratings = trainset.ur[trainset.to_inner_uid(user_id)]\n",
    "    rated_items = [item[0] for item in user_ratings]\n",
    "\n",
    "    # Obtener todas las películas en el dataset\n",
    "    all_items = trainset.all_items()\n",
    "\n",
    "    # Predecir calificaciones para ítems no calificados\n",
    "    predictions = []\n",
    "    for item_id in all_items:\n",
    "        if item_id not in rated_items:\n",
    "            pred = knn_model.predict(str(user_id), trainset.to_raw_iid(item_id))\n",
    "            predictions.append((item_id, pred.est))\n",
    "\n",
    "    # Ordenar las predicciones y tomar las \"n_recommendations\" mejores\n",
    "    predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "    top_recommendations = predictions[:n_recommendations]\n",
    "\n",
    "    return top_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendaciones para el usuario 186: \n",
      "ITEM_ID: 243, Calificación estimada: 4.57\n",
      "ITEM_ID: 283, Calificación estimada: 4.51\n",
      "ITEM_ID: 301, Calificación estimada: 4.48\n",
      "ITEM_ID: 673, Calificación estimada: 4.47\n",
      "ITEM_ID: 172, Calificación estimada: 4.46\n"
     ]
    }
   ],
   "source": [
    "#pred = knn_models.get('msd').predict('186', '302')\n",
    "#pred\n",
    "\n",
    "user_id = str(186)\n",
    "recommendations = recomendacion(user_id=user_id, knn_model=knn_models.get('msd'), n_recommendations=5)\n",
    "\n",
    "print(\"Recomendaciones para el usuario {}: \".format(user_id))\n",
    "for item_id, est_rating in recommendations:\n",
    "    print(f\"ITEM_ID: {item_id}, Calificación estimada: {est_rating:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong>Ejemplo de salida</strong><br><br><span>user: 186        item: 302        r_ui = None   est = 3.98   {'actual_k': 50, 'was_impossible': False}</span>\n",
    "\n",
    "<table>\n",
    "    <thead>\n",
    "        <th>user</th>\n",
    "        <th>item</th>\n",
    "        <th>r_ui</th>\n",
    "        <th>est</th>\n",
    "        <th>Detail</th>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td><span>El ID del usuario para el cual estás haciendo la predicción.</span></td>\n",
    "            <td><span>El ID del ítem (película) para el cual estás haciendo la predicción de rating.</span></td>\n",
    "            <td><span>Este campo representa el valor real del rating que el usuario le dio a este ítem. En este caso es None porque probablemente no se conoce el valor real (puede que sea una predicción para un ítem que el usuario no ha calificado).</span></td>\n",
    "            <td><span>Este es el valor estimado de la predicción, lo que significa que el modelo predice que el usuario 186 probablemente le daría una calificación de 3.98 a la película 302.</span></td>\n",
    "            <td>\n",
    "                <table>\n",
    "                    <thead>\n",
    "                        <th><span>actual_k</span></th>\n",
    "                        <th><span>was_impossible</span></th>\n",
    "                    </thead>\n",
    "                    <tbody>\n",
    "                        <tr>\n",
    "                            <td>\n",
    "                                <span>Indica que el modelo utilizó 50 vecinos cercanos (similar a lo que estableciste en el parámetro k)</span>\n",
    "                            </td>\n",
    "                            <td>\n",
    "                                <span>Esto indica que la predicción fue posible, es decir, el modelo pudo encontrar suficientes vecinos cercanos para hacer la predicción. Si hubiera sido True, significaría que no pudo encontrar suficientes vecinos.</span>\n",
    "                            </td>\n",
    "                        </tr>\n",
    "                    </tbody>\n",
    "                </table>\n",
    "            </td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
