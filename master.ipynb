{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sistema de Recomendación con KNN -> MovieLens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PAQUETES REQUERIDOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pip\n",
    "pip.main(['install', 'tqdm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Implementación de Funciones de Similaridad**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def msd_similarity(u:np.array, v:np.array, max_rating:int, min_rating:int) -> float:\n",
    "    \n",
    "    sum_r = 0 \n",
    "    count = 0\n",
    "    \n",
    "    for i in range(len(u)):\n",
    "        if u[i] != None and v[i] != None:\n",
    "            count += 1\n",
    "            sum_r += math.pow((u[i] - v[i])/(max_rating - min_rating), 2)\n",
    "            \n",
    "    if count > 0:\n",
    "        sim = 1-(sum_r/float(count))\n",
    "        return sim\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def cosine_similarity(u:np.array, v:np.array, max_rating:int, min_rating:int) -> float:\n",
    "    \"\"\"\n",
    "    Calcula la similitud del coseno entre dos vectores.\n",
    "    \n",
    "    Cosine_Similarity = u ⋅ v / |u||v|\n",
    "    \n",
    "    Parameters:\n",
    "        u (list or np.ndarray): Primer vector.\n",
    "        v (list or np.ndarray): Segundo vector.\n",
    "    \n",
    "    Returns:\n",
    "        float: La similitud del coseno o None si no se puede calcular.\n",
    "\n",
    "    \"\"\"\n",
    "    numerador = 0\n",
    "    denominador_u = 0\n",
    "    denominador_v = 0\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for i in range(len(u)):\n",
    "        if u[i] != None and v[i] != None:\n",
    "            numerador += u[i] * v[i]\n",
    "            denominador_u += math.pow(u[i], 2)\n",
    "            denominador_v += math.pow(v[i], 2)\n",
    "            count += 1\n",
    "    if count > 0 and denominador_u != 0 and denominador_v != 0:\n",
    "        cos = numerador / (math.sqrt(denominador_u) * math.sqrt(denominador_v))\n",
    "        return cos\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def correlation_similarity(u, v, max_rating:int, min_rating:int) -> float:\n",
    "    \n",
    "    \"\"\"\n",
    "    Calcula la correlación de Pearson entre dos vectores.\n",
    "    \n",
    "    Correlation_Similarity = cov(u, v) / (σ_u * σ_v)\n",
    "    \n",
    "    Parameters:\n",
    "        u (list or np.ndarray): Primer vector.\n",
    "        v (list or np.ndarray): Segundo vector.\n",
    "    \n",
    "    Returns:\n",
    "        float: La correlación de Pearson o None si no se puede calcular.\n",
    "    \"\"\"\n",
    "\n",
    "    # -- Convertir listas a numpy arrays, reemplazando None por 0\n",
    "    u = np.array(u, dtype=float)\n",
    "    v = np.array(v, dtype=float)\n",
    "\n",
    "    # -- Reemplazar None (o NaN) por 0\n",
    "    u[np.isnan(u)] = 0\n",
    "    v[np.isnan(v)] = 0\n",
    "\n",
    "    # -- Filtrar los índices donde ambos vectores tienen valores no cero\n",
    "    mask = (u != 0) & (v != 0)\n",
    "    \n",
    "    if np.sum(mask) == 0:\n",
    "        return None  # No hay valores en común para calcular la correlación\n",
    "\n",
    "    u_filtered = u[mask]\n",
    "    v_filtered = v[mask]\n",
    "\n",
    "    # -- Calcular la media de los vectores\n",
    "    u_mean = np.mean(u_filtered)\n",
    "    v_mean = np.mean(v_filtered)\n",
    "\n",
    "    # -- Calcular la covarianza\n",
    "    covariance = np.sum((u_filtered - u_mean) * (v_filtered - v_mean))\n",
    "\n",
    "    # -- Calcular las desviaciones estándar\n",
    "    std_u = np.std(u_filtered, ddof=0)\n",
    "    std_v = np.std(v_filtered, ddof=0)\n",
    "\n",
    "    # Si alguna desvicacion estandar es 0 retornamos None\n",
    "    if std_u > 0 and std_v > 0:\n",
    "        return covariance / (std_u * std_v)\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def jmsd_similarity(u, v, max_rating:int, min_rating:int) -> float:\n",
    "    \"\"\"\n",
    "    Calcula la similitud de Jensen-Shannon entre dos vectores.\n",
    "    \n",
    "    La similitud de Jensen-Shannon se define como:\n",
    "    JMSD(u, v) = 1 - D_JS(u, v)\n",
    "    \n",
    "    Donde D_JS(u, v) es la distancia de Jensen-Shannon entre u y v.\n",
    "\n",
    "    Parameters:\n",
    "        u (list or np.ndarray): Primer vector.\n",
    "        v (list or np.ndarray): Segundo vector.\n",
    "    \n",
    "    Returns:\n",
    "        float: La similitud de Jensen-Shannon o None si no se puede calcular.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convertir listas a numpy arrays\n",
    "    u = np.array(u, dtype=float)\n",
    "    v = np.array(v, dtype=float)\n",
    "\n",
    "    # Reemplazar None (o NaN) por 0\n",
    "    u[np.isnan(u)] = 0\n",
    "    v[np.isnan(v)] = 0\n",
    "\n",
    "    # Normalizar los vectores para que sumen 1 (convertir a distribuciones de probabilidad)\n",
    "    u_sum = np.sum(u)\n",
    "    v_sum = np.sum(v)\n",
    "\n",
    "    if u_sum == 0 or v_sum == 0:\n",
    "        return None  # No se puede calcular la similitud si uno de los vectores es cero\n",
    "\n",
    "    # -- Distribución de u\n",
    "    p = u / u_sum\n",
    "    # -- Distribución de v\n",
    "    q = v / v_sum\n",
    "\n",
    "    # Calcular la mezcla de las dos distribuciones\n",
    "    m = 0.5 * (p + q)\n",
    "\n",
    "    # Calcular la divergencia de Kullback-Leibler\n",
    "    def kl_divergence(p, q):\n",
    "        return np.sum(np.where(p != 0, p * np.log(p / q), 0))\n",
    "\n",
    "    # Calcular la distancia de Jensen-Shannon\n",
    "    d_js = 0.5 * kl_divergence(p, m) + 0.5 * kl_divergence(q, m)\n",
    "\n",
    "    # Calcular la similitud de Jensen-Shannon\n",
    "    similarity = 1 - d_js\n",
    "    \n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cálculo de similaridades**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarities(ratings_matrix:np.array, similarity_metric:object, num_users:int, max_rating:int, min_rating:int) -> list:\n",
    "    \"\"\"\n",
    "    Cálculo de similaridades\n",
    "    \"\"\"\n",
    "\n",
    "    # Creamos una matriz con valores de similaridad a -1\n",
    "    similarities = [[float('-inf') for _ in range(num_users)] for _ in range(num_users)]\n",
    "    \n",
    "    # Recorremos la matriz por usuario\n",
    "    for i, u in enumerate(tqdm(ratings_matrix, leave=False)):\n",
    "        for j, v in enumerate(ratings_matrix):\n",
    "            if j != i: # No calculamos la similaridad para un mismo usuario\n",
    "                similarities[i][j] = similarity_metric(u, v, max_rating=max_rating, min_rating=min_rating)\n",
    "        \n",
    "    return similarities\n",
    "\n",
    "def rating_average(ratings) -> float:\n",
    "    \n",
    "    acc = 0\n",
    "    count = 0\n",
    "    for id_item in range(len(ratings)):\n",
    "        if ratings[id_item] != None:\n",
    "            acc += ratings[id_item]\n",
    "            count += 1\n",
    "    return acc / count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cálculo de K-Vecinos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_neighbors(similarities_matrix, k_neighbors, num_users):\n",
    "    \n",
    "    neighbors = [None for _ in range(num_users)]\n",
    "    \n",
    "    for index, similarities in enumerate(tqdm(similarities_matrix, leave=False)):\n",
    "        i_neighbors = [i[0] for i in sorted(enumerate(similarities), \n",
    "                                            key=lambda x:float('-inf') if x[1] is None else x[1], \n",
    "                                            reverse=True)]\n",
    "        neighbors[index] = i_neighbors[0:k_neighbors]\n",
    "\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cálculo de Predicciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(ratings_matrix:np.array, predictions_matrix:np.array):\n",
    "    \"\"\"\n",
    "    Calcula el Error Medio Absoluto (MAE) entre las calificaciones reales y las predicciones.\n",
    "    \n",
    "    Parameters:\n",
    "        ratings_matrix : Matriz de calificaciones reales de los usuarios.\n",
    "        predictions_matrix : Matriz de predicciones de calificaciones.\n",
    "    \n",
    "    Returns:\n",
    "        float: El MAE promedio de todos los usuarios.\n",
    "    \"\"\"\n",
    "    mae_users = []\n",
    "\n",
    "    for user_ratings, user_predictions in zip(ratings_matrix, predictions_matrix):\n",
    "        abs_errors = []\n",
    "        \n",
    "        for real, predicted in zip(user_ratings, user_predictions):\n",
    "            if real is not None and not np.isnan(real):\n",
    "                abs_errors.append(abs(real - predicted))\n",
    "\n",
    "        if abs_errors:\n",
    "            mae_users.append(np.mean(abs_errors))\n",
    "        else:\n",
    "            mae_users.append(None)\n",
    "\n",
    "    # Convertir la lista a numpy array y calcular el MAE ignorando None/NaN\n",
    "    return np.nanmean(np.array(mae_users, dtype=np.float64), axis=0)\n",
    "\n",
    "def calculate_deviation_from_mean_prediction(ratings_matrix:np.array, neighbors:list, num_items:int, num_users:int):\n",
    "    \n",
    "    # Creamos una matriz para el cálculo de predicciones\n",
    "    predictions = [[None for _ in range(num_items)] for _ in range(num_users)]\n",
    "    \n",
    "    # Calculamos la media de los votos de los usuarios\n",
    "    avg_user_ratings = [rating_average(user) for user in ratings_matrix]\n",
    "    \n",
    "    # Recorremos la matriz de votos\n",
    "    for i, u in enumerate(tqdm(ratings_matrix, leave=False)):\n",
    "        for j, v in enumerate(ratings_matrix[0]):\n",
    "            numerador = 0 \n",
    "            denominador = 0\n",
    "            for neighbor in neighbors[i]:\n",
    "                if ratings_matrix[neighbor][j] != None:\n",
    "                    numerador += ratings_matrix[neighbor][j] - avg_user_ratings[neighbor]\n",
    "                    denominador += 1\n",
    "                    \n",
    "            predictions[i][j] = (avg_user_ratings[i] if denominador == 0 \n",
    "                                 else avg_user_ratings[i] + (numerador/denominador))\n",
    "            \n",
    "            # Ajustamos los votos inferiores a 1 y superiores a 5\n",
    "            if predictions[i][j] < 1:\n",
    "                predictions[i][j] = 1\n",
    "            if predictions[i][j] > 5:\n",
    "                predictions[i][j] = 5\n",
    "            \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANALISIS EXPLORATORIO (EDA)**\n",
    "\n",
    "Primero hacemos una exploración descriptiva de nuestros datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CARGA DE DATOS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ratings_matrix(file:str, num_items:int, num_users:int) -> list:\n",
    "    \"\"\"\n",
    "    Data la ruta donde se encuentra un fichero con la estructura [ID_USER::ID_MOVIE::RATING]\n",
    "    crea una matriz de interacción usuario-artículo. \n",
    "    Esta matriz representa las valoraciones que los usuarios han dado a los artículos,\n",
    "    donde las filas representan a los usuarios y las columnas a los artículos.\n",
    "    \n",
    "    Un valor de 0 indica que el usuario no ha valorado el artículo.\n",
    "    \"\"\"\n",
    "\n",
    "    # -- Creamos una lista vacia de NUM_ITEMS elementos por cada usuario \n",
    "    RATINGS = [[None for _ in range(num_items)] for _ in range(num_users)] \n",
    "\n",
    "    # -- Abre el archivo indicado y lee cada línea separando el contenido de estas por el caracter ::\n",
    "    # -- que hace referencia a la estructura ID_USER::ID_MOVIE::RATING\n",
    "    fx = open(file, 'r')\n",
    "    while True:\n",
    "        line = fx.readline()\n",
    "        if not line:\n",
    "            break\n",
    "        else:\n",
    "            l = line.strip()\n",
    "            l = l.split('::')\n",
    "            user_id, movie_id, rating = l\n",
    "\n",
    "            # -- Completar el espacio correspondiente a esta línea en la lista de ratings\n",
    "            RATINGS[int(user_id)][int(movie_id)] = int(rating)\n",
    "\n",
    "    # -- Convierte los valores nulos en 0(cero)\n",
    "    for index in range(len(RATINGS)):\n",
    "        data = RATINGS[index]\n",
    "        RATINGS[index] = [0 if x is None else x for x in data]\n",
    "\n",
    "    return RATINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Número de usuarios e items\n",
    "NUM_USERS = 943\n",
    "NUM_ITEMS = 1682\n",
    "\n",
    "# Notas máximas y mínimas dadas en la matriz de votos\n",
    "MIN_RATING = 1\n",
    "MAX_RATING = 5\n",
    "\n",
    "# Ruta del los datasets de entrenamiento y test\n",
    "TRAIN_RATINGS_FILE = 'movielens_100k_training.txt'\n",
    "TEST_RATINGS_FILE = 'movielens_100k_test.txt'\n",
    "\n",
    "# Lectura de los Datasets de Entrenamiento y Test\n",
    "train_ratings = np.array(read_ratings_matrix(file=TRAIN_RATINGS_FILE, num_items=NUM_ITEMS, num_users=NUM_USERS))\n",
    "test_ratings = np.array(read_ratings_matrix(file=TEST_RATINGS_FILE, num_items=NUM_ITEMS, num_users=NUM_USERS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Normalizar la matriz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_normalized_train_matrix = train_ratings\n",
    "#mean_user_rating_train = np.mean(train_ratings, axis=1).reshape(-1, 1)\n",
    "#rating_normalized_train_matrix = train_ratings - mean_user_rating_train\n",
    "\n",
    "rating_normalized_test_matrix = test_ratings\n",
    "#mean_user_rating_test = np.mean(test_ratings, axis=1).reshape(-1, 1)\n",
    "#rating_normalized_test_matrix = test_ratings - mean_user_rating_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cálculo de similaridad MSD\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f87ed4f78b3486c9e9add0de84f9305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25-Vecinos\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a0a8f2984534f5ba28fc4c61189886f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d147192dd56a4a64b0d1702757340590",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[106], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m predictions \u001b[38;5;241m=\u001b[39m calculate_deviation_from_mean_prediction(ratings_matrix\u001b[38;5;241m=\u001b[39mrating_normalized_train_matrix , neighbors\u001b[38;5;241m=\u001b[39mneighbors_matrix, num_items\u001b[38;5;241m=\u001b[39mNUM_ITEMS, num_users\u001b[38;5;241m=\u001b[39mNUM_USERS)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Calculamos el MAE para entrenamiento y test\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m mae_train \u001b[38;5;241m=\u001b[39m \u001b[43mget_mae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mratings_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrating_normalized_train_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m mae_test \u001b[38;5;241m=\u001b[39m get_mae(ratings_matrix\u001b[38;5;241m=\u001b[39mrating_normalized_test_matrix, predictions_matrix\u001b[38;5;241m=\u001b[39mpredictions)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Añadimos los experimentos a la lista\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[102], line 27\u001b[0m, in \u001b[0;36mget_mae\u001b[1;34m(ratings_matrix, predictions_matrix)\u001b[0m\n\u001b[0;32m     24\u001b[0m         mae_users\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Convertir la lista a numpy array y calcular el MAE ignorando None/NaN\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnanmean(np\u001b[38;5;241m.\u001b[39marray(mae_users, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ingjo\\anaconda3\\Lib\\site-packages\\numpy\\__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    300\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;66;03m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;66;03m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    311\u001b[0m \u001b[38;5;66;03m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;66;03m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "# Metricas, K vecinos y predicciones a probar\n",
    "SIMILARITIES_METRICS = [('MSD', msd_similarity), \n",
    "                        ('COSENO', cosine_similarity),\n",
    "                        ('CORRELACION', correlation_similarity),\n",
    "                        ('JMSD', jmsd_similarity)]\n",
    "K_NEIGHBORS = [25, 50, 75, 100, 150, 200, 250, 300, 500]\n",
    "\n",
    "# Guardo en una lista los experimentos realizados, siendo un experimento una lista con 4 posiciones:\n",
    "#     1.- Métrica de similaridad\n",
    "#     2.- Número de vecinos\n",
    "#     3.- MAE\n",
    "#     4.- Entrenamiento o Test\n",
    "experiments = []\n",
    "\n",
    "for metric in SIMILARITIES_METRICS:\n",
    "    print(f'Cálculo de similaridad {metric[0]}')\n",
    "    similarities_matrix = calculate_similarities(ratings_matrix=rating_normalized_train_matrix , similarity_metric=metric[1], num_users=NUM_USERS, max_rating=MAX_RATING, min_rating=MIN_RATING)\n",
    "\n",
    "    for k in K_NEIGHBORS:\n",
    "        print(f'{k}-Vecinos')\n",
    "        neighbors_matrix = calculate_neighbors(similarities_matrix=similarities_matrix, k_neighbors=k, num_users=NUM_USERS)\n",
    "        \n",
    "        # Calculamos las predicciones\n",
    "        predictions = calculate_deviation_from_mean_prediction(ratings_matrix=rating_normalized_train_matrix , neighbors=neighbors_matrix, num_items=NUM_ITEMS, num_users=NUM_USERS)\n",
    "        \n",
    "        # Calculamos el MAE para entrenamiento y test\n",
    "        mae_train = get_mae(ratings_matrix=rating_normalized_train_matrix, predictions_matrix=predictions)\n",
    "        mae_test = get_mae(ratings_matrix=rating_normalized_test_matrix, predictions_matrix=predictions)\n",
    "        \n",
    "        # Añadimos los experimentos a la lista\n",
    "        experiments.append([metric[0], k, mae_train, \"Train\"])\n",
    "        experiments.append([metric[0], k, mae_test, \"Test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Pasamos los resultados de los experimentos a un DataFrame\n",
    "df_results = pd.DataFrame.from_records(experiments, columns=['Métrica', 'K-Vecinos', 'MAE', 'Train/Test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Mostramos los resultados de los experimentos con los datos de entrenamiento\n",
    "pd.pivot_table(df_results[df_results['Train/Test']=='Train'], values=['MAE'], index=['K-Vecinos'], columns=['Métrica'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Muestra los resultados de los experimentos con los datos de test\n",
    "pd.pivot_table(df_results[df_results['Train/Test']=='Test'], values=['MAE'], index=['K-Vecinos'], columns=['Metrica'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Graficar resultados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Gráfica del MAE(Mean Absolute Error) con los datos de Entrenamiento\n",
    "plt.subplots(figsize = (20, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('MAE vs K-Vecinos (Train)')\n",
    "sns.lineplot(x=\"K-Vecinos\", y=\"MAE\", hue=\"Métrica\", data=df_results[df_results['Train/Test']=='Train'])\n",
    "\n",
    "# -- Gráfica del MAE(Mean Absolute Error) con los datos de Test\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('MAE vs K-Vecinos (Test)')\n",
    "sns.lineplot(x=\"K-Vecinos\", y=\"MAE\", hue=\"Métrica\", data=df_results[df_results['Train/Test']=='Test'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entrenar el modelo KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = NearestNeighbors(n_neighbors=5, metric='cosine')\n",
    "knn.fit(rating_normalized_train_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encontrar los K-Neighbors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encuentra los K-Vecinos de un user_id determinado\n",
    "target_user_index = 0\n",
    "distances, indices = knn.kneighbors(rating_normalized_train_matrix[target_user_index].reshape(1, -1), n_neighbors=5)\n",
    "data = pd.DataFrame({'distances':distances[0], 'indices':indices[0]})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cálculo de Recomendaciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendacion(user_index:int, n_recommendations:int) -> list:\n",
    "    \"\"\"\n",
    "    Devuelve una lista de N identificadores respecto a las películas recomendadas al usuario identificado por un ID.\n",
    "    \"\"\"\n",
    "    distances, indices = knn.kneighbors(train_ratings[user_index].reshape(1, -1), n_neighbors=n_recommendations)\n",
    "    \n",
    "    recommended_users = []\n",
    "    for i in range(1, len(distances.flatten())):\n",
    "        recommended_users.append(indices.flatten()[i])\n",
    "    \n",
    "    return recommended_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recomendaciones = recomendacion(user_index=0, n_recommendations=5)\n",
    "print(recomendaciones)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
